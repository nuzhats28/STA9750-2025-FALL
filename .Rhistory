# URLs for CSV downloads
risk_url <- "https://data.cityofnewyork.us/resource/259a-b6s7.csv?$limit=50000"
work_url <- "https://data.cityofnewyork.us/resource/bdjm-n7q4.csv?$limit=50000"
# Download only if not already present
if (!file.exists(risk_file)) {
message("Downloading risk assessments CSV ...")
download.file(risk_url, risk_file, mode = "wb")
} else {
message("Risk assessments CSV already exists â€” skipping download.")
}
if (!file.exists(work_file)) {
message("Downloading work orders CSV ...")
download.file(work_url, work_file, mode = "wb")
} else {
message("Work orders CSV already exists â€” skipping download.")
}
# Read CSVs
library(readr)
risk_data <- read_csv(risk_file, show_col_types = FALSE)
work_data <- read_csv(work_file, show_col_types = FALSE)
# (do nothing â€” just remove the preview lines)
# Extra Credit #2: Polite CSV download using download.file
# Create directory if needed
dir.create("data/mp03", showWarnings = FALSE)
# File paths
risk_file <- "data/mp03/risk_assessments.csv"
work_file <- "data/mp03/work_orders.csv"
# URLs for CSV downloads
risk_url <- "https://data.cityofnewyork.us/resource/259a-b6s7.csv?$limit=50000"
work_url <- "https://data.cityofnewyork.us/resource/bdjm-n7q4.csv?$limit=50000"
# Download only if not already present
if (!file.exists(risk_file)) {
message("Downloading risk assessments CSV ...")
download.file(risk_url, risk_file, mode = "wb")
} else {
message("Risk assessments CSV already exists â€” skipping download.")
}
if (!file.exists(work_file)) {
message("Downloading work orders CSV ...")
download.file(work_url, work_file, mode = "wb")
} else {
message("Work orders CSV already exists â€” skipping download.")
}
# Read CSVs
library(readr)
risk_data <- read_csv(risk_file, show_col_types = FALSE)
work_data <- read_csv(work_file, show_col_types = FALSE)
# (do nothing â€” just remove the preview lines)
# Extra Credit #2: Polite CSV download using download.file
# Create directory if needed
dir.create("data/mp03", showWarnings = FALSE)
# File paths
risk_file <- "data/mp03/risk_assessments.csv"
work_file <- "data/mp03/work_orders.csv"
# URLs for CSV downloads
risk_url <- "https://data.cityofnewyork.us/resource/259a-b6s7.csv?$limit=50000"
work_url <- "https://data.cityofnewyork.us/resource/bdjm-n7q4.csv?$limit=50000"
# Download only if not already present
if (!file.exists(risk_file)) {
message("Downloading risk assessments CSV ...")
download.file(risk_url, risk_file, mode = "wb")
} else {
message("Risk assessments CSV already exists â€” skipping download.")
}
if (!file.exists(work_file)) {
message("Downloading work orders CSV ...")
download.file(work_url, work_file, mode = "wb")
} else {
message("Work orders CSV already exists â€” skipping download.")
}
# Read CSVs
library(readr)
risk_data <- read_csv(risk_file, show_col_types = FALSE)
work_data <- read_csv(work_file, show_col_types = FALSE)
head(risk_data)
head(work_data)
# ----------------------------------------------------------------------------
# Task 2: Download & Read NYC Tree Points
# ----------------------------------------------------------------------------
library(httr2)
library(sf)
library(dplyr)
# Create directory if needed
dir.create("data/mp03", recursive = TRUE, showWarnings = FALSE)
# Base API URL (GeoJSON endpoint)
base_url <- "https://data.cityofnewyork.us/resource/hn5i-inap.geojson"
# Parameters
limit <- 50000   # number of rows per request (adjustable)
offset <- 0      # starting row
page <- 1        # page counter
tree_files <- c()  # list to store downloaded files
repeat {
# File path for this page
file_path <- sprintf("data/mp03/tree_points_%03d.geojson", page)
# Skip download if file exists
if (!file.exists(file_path)) {
message(sprintf("â¬‡ï¸ Downloading trees %d to %d...", offset + 1, offset + limit))
# API request with limit & offset
req <- request(base_url) %>%
req_url_query(`$limit` = limit, `$offset` = offset)
# Fetch data and save
resp <- req_perform(req)
writeBin(resp$body, file_path)
} else {
message(sprintf("âœ… File %s already exists â€” skipping.", file_path))
}
# Read the GeoJSON page
trees_page <- st_read(file_path, quiet = TRUE)
# Store in list
tree_files <- append(tree_files, list(trees_page))
# If fewer than limit returned, we reached the end
if (nrow(trees_page) < limit) break
# Prepare next page
offset <- offset + limit
page <- page + 1
}
# ----------------------------------------------------------------------------
# Task 2: Download & Read NYC Tree Points
# ----------------------------------------------------------------------------
library(httr2)
library(sf)
library(dplyr)
# Create directory if needed
dir.create("data/mp03", recursive = TRUE, showWarnings = FALSE)
# Base API URL (GeoJSON endpoint)
base_url <- "https://data.cityofnewyork.us/resource/hn5i-inap.geojson"
# Parameters
limit <- 50000   # number of rows per request (adjustable)
offset <- 0      # starting row
page <- 1        # page counter
tree_files <- c()  # list to store downloaded files
repeat {
# File path for this page
file_path <- sprintf("data/mp03/tree_points_%03d.geojson", page)
# Skip download if file exists
if (!file.exists(file_path)) {
message(sprintf("â¬‡ï¸ Downloading trees %d to %d...", offset + 1, offset + limit))
# API request with limit & offset
req <- request(base_url) %>%
req_url_query(`$limit` = limit, `$offset` = offset)
# Fetch data and save
resp <- req_perform(req)
writeBin(resp$body, file_path)
} else {
message(sprintf("âœ… File %s already exists â€” skipping.", file_path))
}
# Read the GeoJSON page
trees_page <- st_read(file_path, quiet = TRUE)
# Store in list
tree_files <- append(tree_files, list(trees_page))
# If fewer than limit returned, we reached the end
if (nrow(trees_page) < limit) break
# Prepare next page
offset <- offset + limit
page <- page + 1
}
# Combine all pages into one sf object
nyc_trees <- bind_rows(tree_files)
# Optional: preview
message("âœ… NYC Tree Points downloaded and combined successfully!")
print(nyc_trees %>% slice_head(n = 5))
# ----------------------------------------------------------------------------
# Task 3: Map NYC Trees over City Council Districts
# ----------------------------------------------------------------------------
library(ggplot2)
library(sf)
# Ensure datasets are in the same CRS
nyc_trees <- st_transform(nyc_trees, st_crs(nycc_districts))
# Optional: for faster plotting, sample a subset of trees
# Comment out slice_sample for full dataset
trees_sample <- nyc_trees %>% slice_sample(n = 50000)  # 50k points
# Plot
ggplot() +
# Council district boundaries layer
geom_sf(data = nycc_districts, fill = NA, color = "black", size = 0.4) +
# Tree points layer
geom_sf(data = trees_sample, aes(), color = "forestgreen", size = 0.5, alpha = 0.3) +
# Titles and labels
labs(title = "NYC Tree Points Over City Council Districts",
subtitle = "Sample of 50,000 trees for visualization clarity",
caption = "Data Source: NYC OpenData") +
theme_minimal()
quarto::quarto_render("mp03.qmd", output_file = "docs/mp03.html")
getwd()
quarto::quarto_render("mp03.qmd")
system("git add mp03.qmd docs/mp03.html")
system('git commit -m "Add MP03 Quarto submission"')
system("git push origin main")
system("git pull origin main --rebase")
system("git status")
system("git add .")
system("git rebase --continue")
system("git status")
system("git rebase --abort")
system("git status")
quarto::quarto_render("mp03.qmd")
library(sf)
library(tidyverse)
# Create data directory if needed
if (!dir.exists("data/mp03")) {
dir.create("data/mp03", recursive = TRUE)
}
library(sf)
library(tidyverse)
# Create data directory if needed
if (!dir.exists("data/mp03")) {
dir.create("data/mp03", recursive = TRUE)
}
# Define file paths
zip_path <- "data/mp03/nycc.zip"
unzip_dir <- "data/mp03/nycc_shp"
# Updated NYC Planning Council District shapefile URL (2025)
url_primary <- "https://data.cityofnewyork.us/download/gqij-kd3p/application/zip"
library(sf)
library(dplyr)
# Create data directory
if (!dir.exists("data/mp03")) {
dir.create("data/mp03", recursive = TRUE)
}
# File paths
geojson_path <- "data/mp03/nycc_districts.geojson"
# Official download URL (GeoJSON version) for City Council Districts
url_primary <- "https://services5.arcgis.com/GfwWNkhOj9bNBqoJ/ArcGIS/rest/services/NYC_City_Council_Districts/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=geojson"
# Download if not already present
if (!file.exists(geojson_path)) {
message("â¬‡ï¸ Downloading NYC City Council boundaries (GeoJSON)...")
download.file(url_primary, destfile = geojson_path, mode = "wb")
} else {
message("âœ… GeoJSON file already exists â€” skipping download.")
}
# Read the GeoJSON into an sf object
message("ðŸ“– Reading NYC City Council GeoJSON file...")
nycc_districts <- st_read(geojson_path, quiet = TRUE)
# Transform CRS to WGS84 (lat/long)
nycc_districts <- st_transform(nycc_districts, crs = "WGS84")
# Rename the column 'CounDist' â†’ 'coun_dist' for consistency
nycc_districts <- nycc_districts %>%
rename(coun_dist = CounDist)
# Optional: simplify geometry for faster plotting (especially if dataset is large)
nycc_districts <- nycc_districts %>%
mutate(geometry = st_simplify(geometry, dTolerance = 5))
# Preview the data
message("âœ… Data loaded and transformed successfully!")
print(nycc_districts %>% select(coun_dist) %>% head())
# Quick plot to verify boundaries
plot(st_geometry(nycc_districts),
main = "NYC City Council District Boundaries (Simplified)",
col = "lightgreen",
border = "gray40")
# ----------------------------------------------------------------------------
# Task 2: Download & Read NYC Tree Points
# ----------------------------------------------------------------------------
library(httr2)
library(sf)
library(dplyr)
# Create directory if needed
dir.create("data/mp03", recursive = TRUE, showWarnings = FALSE)
# Base API URL (GeoJSON endpoint)
base_url <- "https://data.cityofnewyork.us/resource/hn5i-inap.geojson"
# Parameters
limit <- 50000   # number of rows per request (adjustable)
offset <- 0      # starting row
page <- 1        # page counter
tree_files <- c()  # list to store downloaded files
repeat {
# File path for this page
file_path <- sprintf("data/mp03/tree_points_%03d.geojson", page)
# Skip download if file exists
if (!file.exists(file_path)) {
message(sprintf("â¬‡ï¸ Downloading trees %d to %d...", offset + 1, offset + limit))
# API request with limit & offset
req <- request(base_url) %>%
req_url_query(`$limit` = limit, `$offset` = offset)
# Fetch data and save
resp <- req_perform(req)
writeBin(resp$body, file_path)
} else {
message(sprintf("âœ… File %s already exists â€” skipping.", file_path))
}
# Read the GeoJSON page
trees_page <- st_read(file_path, quiet = TRUE)
# Store in list
tree_files <- append(tree_files, list(trees_page))
# If fewer than limit returned, we reached the end
if (nrow(trees_page) < limit) break
# Prepare next page
offset <- offset + limit
page <- page + 1
}
# Combine all pages into one sf object
nyc_trees <- bind_rows(tree_files)
# Optional: preview
message("âœ… NYC Tree Points downloaded and combined successfully!")
print(nyc_trees %>% slice_head(n = 5))
# ----------------------------------------------------------------------------
# Task 2: Download & Read NYC Tree Points
# ----------------------------------------------------------------------------
library(httr2)
library(sf)
library(dplyr)
# Create directory if needed
dir.create("data/mp03", recursive = TRUE, showWarnings = FALSE)
# Base API URL (GeoJSON endpoint)
base_url <- "https://data.cityofnewyork.us/resource/hn5i-inap.geojson"
# Parameters
limit <- 50000   # number of rows per request (adjustable)
offset <- 0      # starting row
page <- 1        # page counter
tree_files <- c()  # list to store downloaded files
repeat {
# File path for this page
file_path <- sprintf("data/mp03/tree_points_%03d.geojson", page)
# Skip download if file exists
if (!file.exists(file_path)) {
message(sprintf("â¬‡ï¸ Downloading trees %d to %d...", offset + 1, offset + limit))
# API request with limit & offset
req <- request(base_url) %>%
req_url_query(`$limit` = limit, `$offset` = offset)
# Fetch data and save
resp <- req_perform(req)
writeBin(resp$body, file_path)
} else {
message(sprintf("âœ… File %s already exists â€” skipping.", file_path))
}
# Read the GeoJSON page
trees_page <- st_read(file_path, quiet = TRUE)
# Store in list
tree_files <- append(tree_files, list(trees_page))
# If fewer than limit returned, we reached the end
if (nrow(trees_page) < limit) break
# Prepare next page
offset <- offset + limit
page <- page + 1
}
# Combine all pages into one sf object
nyc_trees <- bind_rows(tree_files)
# Optional: preview
message("âœ… NYC Tree Points downloaded and combined successfully!")
print(nyc_trees %>% slice_head(n = 5))
# ----------------------------------------------------------------------------
# Task 3: Map NYC Trees over City Council Districts
# ----------------------------------------------------------------------------
library(ggplot2)
library(sf)
# Ensure datasets are in the same CRS
nyc_trees <- st_transform(nyc_trees, st_crs(nycc_districts))
# Optional: for faster plotting, sample a subset of trees
# Comment out slice_sample for full dataset
trees_sample <- nyc_trees %>% slice_sample(n = 50000)  # 50k points
# Plot
ggplot() +
# Council district boundaries layer
geom_sf(data = nycc_districts, fill = NA, color = "black", size = 0.4) +
# Tree points layer
geom_sf(data = trees_sample, aes(), color = "forestgreen", size = 0.5, alpha = 0.3) +
# Titles and labels
labs(title = "NYC Tree Points Over City Council Districts",
subtitle = "Sample of 50,000 trees for visualization clarity",
caption = "Data Source: NYC OpenData") +
theme_minimal()
# Load libraries
library(sf)
library(dplyr)
# Ensure CRS is consistent
nyc_trees <- st_transform(nyc_trees, st_crs(nycc_districts))
# Spatial join: assign each tree to its district
trees_with_district <- st_join(nyc_trees, nycc_districts, join = st_within)
tree_counts <- trees_with_district %>%
st_drop_geometry() %>%
group_by(coun_dist) %>%
summarise(tree_count = n()) %>%
arrange(desc(tree_count))
most_trees_district <- tree_counts$coun_dist[1]
most_trees_count <- tree_counts$tree_count[1]
message(sprintf("District with most trees: %s (%d trees)",
most_trees_district, most_trees_count))
trees_density <- trees_with_district %>%
st_drop_geometry() %>%
group_by(coun_dist, Shape__Area) %>%
summarise(tree_count = n(), .groups = "drop") %>%
mutate(density = tree_count / Shape__Area) %>%
arrange(desc(density))
highest_density_district <- trees_density$coun_dist[1]
highest_density <- trees_density$density[1]
message(sprintf("District with highest tree density: %s (%.4f trees per mÂ²)",
highest_density_district, highest_density))
dead_fraction <- trees_with_district %>%
st_drop_geometry() %>%
group_by(coun_dist) %>%
summarise(
total = n(),
dead = sum(tolower(tpcondition) == "dead", na.rm = TRUE),
.groups = "drop"
) %>%
mutate(dead_frac = dead / total) %>%
arrange(desc(dead_frac))
highest_dead_district <- dead_fraction$coun_dist[1]
highest_dead_fraction <- dead_fraction$dead_frac[1]
message(sprintf("District with highest fraction of dead trees: %s (%.2f%%)",
highest_dead_district, highest_dead_fraction*100))
# Add borough column based on district
trees_with_district <- trees_with_district %>%
mutate(borough = case_when(
coun_dist %in% 1:10 ~ "Manhattan",
coun_dist %in% 11:18 ~ "Bronx",
coun_dist %in% 19:32 ~ "Queens",
coun_dist %in% 33:48 ~ "Brooklyn",
coun_dist %in% 49:51 ~ "Staten Island",
TRUE ~ NA_character_
))
most_common_manhattan_species <- trees_with_district %>%
filter(borough == "Manhattan") %>%
st_drop_geometry() %>%
group_by(genusspecies) %>%
summarise(n = n(), .groups = "drop") %>%
arrange(desc(n)) %>%
slice(1) %>%
pull(genusspecies)
message(sprintf("Most common tree species in Manhattan: %s", most_common_manhattan_species))
# Add borough column based on district
trees_with_district <- trees_with_district %>%
mutate(borough = case_when(
coun_dist %in% 1:10 ~ "Manhattan",
coun_dist %in% 11:18 ~ "Bronx",
coun_dist %in% 19:32 ~ "Queens",
coun_dist %in% 33:48 ~ "Brooklyn",
coun_dist %in% 49:51 ~ "Staten Island",
TRUE ~ NA_character_
))
most_common_manhattan_species <- trees_with_district %>%
filter(borough == "Manhattan") %>%
st_drop_geometry() %>%
group_by(genusspecies) %>%
summarise(n = n(), .groups = "drop") %>%
arrange(desc(n)) %>%
slice(1) %>%
pull(genusspecies)
message(sprintf("Most common tree species in Manhattan: %s", most_common_manhattan_species))
# Function to create an sf point for Baruch College
new_st_point <- function(lat, lon, ...) {
st_sfc(st_point(c(lon, lat)), crs = 4326)
}
# Baruch College coordinates: 40.7397 N, -73.9835 W
baruch_point <- new_st_point(40.7397, -73.9835)
# Compute distance from each tree to Baruch College and find the closest
closest_tree <- trees_with_district %>%
mutate(distance = st_distance(geometry, baruch_point)) %>%
arrange(distance) %>%
slice(1) %>%
st_drop_geometry()
closest_species <- closest_tree$genusspecies
message(sprintf("Species of tree closest to Baruch College: %s", closest_species))
# Filter Queens district (example: District 25 in Queens)
queens_district <- trees_with_district %>% filter(coun_dist == 25)
# Filter for London Plane trees
plane_trees <- queens_district %>% filter(genusspecies == "Platanus Ã— acerifolia")
library(ggplot2)
ggplot() +
geom_sf(data = nycc_districts %>% filter(coun_dist == 25), fill = "lightgreen", color = "darkgreen") +
geom_sf(data = plane_trees, aes(color = genusspecies), size = 0.8, alpha = 0.7) +
labs(title = "London Plane Trees in Queens District 25",
subtitle = "Proposed tree planting project",
color = "Tree Species") +
theme_minimal()
library(stringr)
# Compare number of London Plane trees across 4 Queens districts
comparison_districts <- trees_with_district %>%
filter(coun_dist %in% c(25, 24, 23, 26)) %>%  # Queens districts
st_drop_geometry() %>%
group_by(coun_dist) %>%
summarise(
total_plane = sum(str_detect(tolower(genusspecies), "platanus"), na.rm = TRUE),
.groups = "drop"
)
# Bar chart
ggplot(comparison_districts, aes(x = factor(coun_dist), y = total_plane, fill = factor(coun_dist))) +
geom_col() +
labs(title = "London Plane Trees Across Selected Queens Districts",
x = "District",
y = "Number of Trees") +
theme_minimal() +
theme(legend.position = "none")
# Another Queens district for comparison (e.g., District 24)
other_district <- nycc_districts %>% filter(coun_dist == 24)
ggplot() +
geom_sf(data = other_district, fill = "lightblue", color = "darkblue") +
geom_sf(data = nycc_districts %>% filter(coun_dist == 25), fill = NA, color = "red", size = 1) +
geom_sf(data = plane_trees, aes(color = genusspecies), size = 0.8, alpha = 0.7) +
labs(title = "London Plane Trees: District 25 vs District 24") +
theme_minimal()
# Extra Credit: Interactive Tree Map with Leaflet
library(leaflet)
# Create a leaflet map of all trees
leaflet() %>%
addProviderTiles(providers$CartoDB.Positron) %>%
addPolygons(data = nycc_districts,
color = "darkgreen",
weight = 1,
fillOpacity = 0.1,
label = ~paste("District:", coun_dist)) %>%
addCircleMarkers(data = trees_with_district,
radius = 2,
color = "forestgreen",
stroke = FALSE,
fillOpacity = 0.5,
popup = ~paste("Species:", genusspecies,
"<br>Condition:", tpcondition)) %>%
setView(lng = -73.94, lat = 40.70, zoom = 10) %>%
addLegend(position = "bottomright",
colors = "forestgreen",
labels = "Trees",
title = "NYC Trees")
